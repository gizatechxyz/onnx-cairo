<<<<<<< HEAD
# ONNX Cairo operators :sparkles:

**ONNX Runtime inference** can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)

In this repository you can find the new ONNX Runtime built using [Cairo](https://www.cairo-lang.org/). The purpose of this repository is to provide the runtime implementation for verfiable ML model inferences using STARKs.

## Getting Started

New contributors are welcome to implement new ONNX Operators in Cairo 1.0! To learn about ONNX Cairo Runtime, how to develop and make a contribution, please check our docs.
=======
# docs

>>>>>>> 37fc87d373c581d0d8ff72c53fd725854c5dcb52
