# ONNX Cairo Runtime :sparkles:

**ONNX Runtime inference** can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms. [Learn more &rarr;](https://www.onnxruntime.ai/docs/#onnx-runtime-for-inferencing)

In this repository you can find the new ONNX Runtime built using [Cairo](https://www.cairo-lang.org/). The purpose of this repository is to provide the runtime implementation for verfiable ML model inferences using STARKs.

✨🚀 **New contributors are welcome to implement new ONNX Operators in Cairo 1.0!** 🌟💡

## 📚 How to use our docs
 
- ⚙️ **ONNX Cairo Runtime** includes our Getting Started guide, API Reference, and more advances features of the core like Tensor, Operators and OPtimizations.

- 🧩 **Algorithms** is an open collection of algorithms implemented using the ONNX Cairo Runtime to be used by the community.

- 🧠 **Knowledge base** is a self-serve library of tips, step-by-step tutorials, and articles that answer your questions about creating verifiable ML models in Cairo.

## 🌟 What's new

For a detailed list of changes, please refer to the [CHANGELOG](./CHANGELOG.md) file.

## 🤝 Join the community!

Join the community and help build a safer and transparent AI in our [Discord](https://discord.gg/Kt24CsMb5k)!

## ✍️ Authors & contributors

For a full list of all authors and contributors, see [the contributors page](https://github.com/franalgaba/onnx-cairo/graphs/contributors).

## License

This project is licensed under the **MIT license**.

See [LICENSE](../LICENSE) for more information.